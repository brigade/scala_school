---
prev: finagle.textile
title: Searchbird
layout: post
---

We're going to build a simple distributed search engine using Scala and the previously discussed "Finagle":http://github.com/twitter/finagle framework.

h3. Design goals: the big picture

Broadly, our design goals include _abstraction_ (the ability to use the resulting system without knowing all of its internal detail); _modularity_ (the ability to factor the system into smaller, simpler pieces that can be more easily understood and/or replaced with other pieces); and _scalability_ (the ability to grow the capacity of the system in a straightforward way).

The system we're going to describe has three pieces: (1) _clients_ that makes requests to (2) _servers_, which send responses to the request; and a (3) _transport_ mechanism that packages up these communications. Normally the client and server would be located on different machines and communicate over a network on a particular numerical "_port_":http://en.wikipedia.org/wiki/Port_(computer_networking), but in this example, they will run on the same machine (and still communicate using ports). In our example, clients and servers will be written in Scala, and the transport will be handled using "Thrift":http://thrift.apache.org/. The primary purpose of this tutorial is to show a simple server and client that can be extended to provide scalable performance. 

To get started, clone our skeleton project "here":https://github.com/brigade/scala_school/tree/master/searchbird_skeleton

Before we look at code, we're going to run a client and server to see how it works.


Since the Searchbird service is a "Thrift":http://thrift.apache.org/ service (like most of our services), its external interface is defined in the Thrift IDL ("interface description language").

h5. src/main/thrift/searchbird.thrift

<pre>
namespace java brigade.searchbird.thrift
namespace rb Searchbird

/**
 * It's considered good form to declare an exception type for your service.
 * Thrift will serialize and transmit them transparently.
 */
exception SearchbirdException {
  1: string description
}

/**
 * A simple memcache-like service, which stores strings by key/value.
 * You should replace this with your actual service.
 */
service SearchbirdService {
  string get(1: string key) throws(1: SearchbirdException ex)

  void put(1: string key, 2: string value)

  list<string> search(1: string query)
}
</pre>

This is pretty straightforward: our service @SearchbirdService@ exports 3 RPC methods, @get@, @put@ and @search@. They comprise a simple interface to a key-value store with search.

In the first window, run the @run@ script

<pre>
$ ./run
...
I 1118 03:36:52.875 THREAD9: Serving admin http on 0.0.0.0/0.0.0.0:9990
I 1118 03:36:52.902 THREAD9: Finagle version 6.30.0 (rev=745578b931893c432e51da623287144e548cc489) built at 20151015-163818
...
</pre>

The service is served on port 9999 on our local machine, while the Admin HTTP interface is served on 9990. Clients can communicate with this service by connecting to port 9999.

Let's do this now with at the Maven console:

<pre>
$ mvn scala:console
...
</pre>

Create client object @client@ connected to port 9999 on our local computer, and can talk to the service that we previously started on that port. Let's send it some requests:

Note that our client class is blocking and meant for console use only, you can still access the non-blocking interface @client.service@.

<pre>
scala> import brigade.searchbird.BlockingClient
import brigade.searchbird.BlockingClient

scala> val client = new Client()

scala> client.put("1", "We should ban guns")
org.apache.thrift.TApplicationException: Internal error processing put: 'scala.NotImplementedError: an implementation is missing'
....
</pre>

Great! we need to start implementing.

Also, you can go http://localhost:9990/admin/ to check out our server's admin interface.

h5. .../Server.scala

Executing the "./run" script compiles our code and runs the @main@ method, which configures and instantiates this server.

<pre>
object Server extends TwitterServer {

  def main() {
    val impl = new SearchbirdServiceImpl
    val server = Thrift.server
      .serveIface(new InetSocketAddress(9999), impl)
    Await.ready(server)
  }
}
</pre>

h5. .../SearchbirdServiceImpl.scala

This is the meat of the service: we extend the thrift-generated @SearchbirdService.FutureIface@ with our custom implementation. Recall that @SearchbirdService.ThriftServer@ has been created for us by the thrift code generator. It generates a scala method per thrift method. In our example so far, the generated interface is:

<pre>
class SearchbirdServiceImpl extends SearchbirdService.FutureIface {

  override def get(key: String): Future[String] = ???

  override def put(key: String, value: String): Future[Unit] = ???

  override def search(query: String): Future[Seq[String]] = ???
}
</pre>

@Future[Value]@s are returned instead of the values directly so that their computation may be deferred (finagle's "documentation":finagle.html has more details on @Future@). For the purpose of this tutorial, the only thing you need to know about a @Future@ is that you can retrieve its value with @Await#result@. 


h2. A simple search engine

Now we'll extend our example so far to create a simple search engine. If we have time, we'll then extend it further to become a _distributed_ search engine consisting of multiple shards so that we can fit a corpus larger than what can fit in the memory of a single machine. 

To keep things simple, we'll extend our current thrift service minimally in order to support a search operation. The usage model is to @put@ documents into the search engine, where each document contains a series of tokens (words); then we can search on a string of tokens to return all documents that contain all tokens in the set. The architecture is identical to the previous example but for the addition of a new @search@ call.

!searchbird-2.svg(Searchbird implementation, revision 2)!

h5. .../SearchbirdServiceImpl.scala

Most of our changes take place in this file.

The current @database@ hashmap holds a forward index that maps a key to a document. We rename it to @forward@ and add a second map for the @reverse@ index (that maps a token to the set of documents that contain that token). So, within @SearchbirdServiceImpl.scala@, replace the @database@ definition with:

<pre>
val forward = new ConcurrentHashMap[String, String].asScala
val reverse = new ConcurrentHashMap[String, Set[String]].asScala
</pre>

Within the @get@ call, replace @database@ with @forward@, but otherwise, @get@ remains the same (it only performs forward lookups). However, @put@ requires changes: we also need to populate the reverse index for each token in the document by appending the document key to the list associated with that token. Replace the @put@ call with the following code. Given a particular search token, we can now use the @reverse@ map to look up documents.

<pre>
def put(key: String, value: String) = {
  forward.put(key, value)

  // serialize updaters
  synchronized {
    value.split(" ").toSet foreach { token =>
      val current = reverse.getOrElse(token, Set())
      reverse(token) = current + key
    }
  }

  Future.Unit
}
</pre>

Note that (even though the @ConcurrentHashMap@ is thread-safe) only one thread can update the @reverse@ map at a time to ensure that read-modify-write of a particular map entry is an atomic operation. (The code is overly conservative; it locks the entire map rather than locking each individual retrieve-modify-write operation.) Also note the use of @Set@ as the data structure; this ensures that if the same token appears twice in a document, it will only be processed by the @foreach@ loop once. 

The implementation still has an issue that is left as an exercise for the reader: when we overwrite a key with a new document, we don't remove any references to the old document in the reverse index.

Now to the meat of the search engine: the new @search@ method. It should tokenize its query, look up all of the matching documents and, then intersect these lists. This will yield the list of documents that contain all of the tokens in the query. This is straightforward to express in Scala; add this to the @SearchbirdServiceImpl@ class:

<pre>
def search(query: String) = Future.value {
  val tokens = query.split(" ")
  val hits = tokens.map { token => reverse.getOrElse(token, Set()) }
  val intersected = hits.reduceLeftOption { _ & _ } getOrElse Set()
  intersected.toList
}
</pre>

A few things are worth calling out in this short piece of code. When constructing the hit list, if the key (@token@) is not found, @getOrElse@ will supply the value from its second parameter (in this case, an empty @Set@). We perform the actual intersection using a left-reduce. The particular flavor, @reduceLeftOption@, will not attempt to perform the reduce if @hits@ is empty, returning instead @None@. This allows us to supply a default value instead of experiencing an exception. In fact, this is equivalent to:

<pre>
def search(query: String) = Future.value {
  val tokens = query.split(" ")
  val hits = tokens.map { token => reverse.getOrElse(token, Set()) }
  if (hits.isEmpty)
    Nil
  else
    hits.reduceLeft { _ & _ } toList
}
</pre>

Which to use is mostly a matter of taste, though functional style often eschews conditionals for sensible defaults.

We can now experiment with our new implementation using the console. Start your server again:

<pre>
$ ./run
...
I 1118 03:36:52.875 THREAD9: Serving admin http on 0.0.0.0/0.0.0.0:9990
I 1118 03:36:52.902 THREAD9: Finagle version 6.30.0 (rev=745578b931893c432e51da623287144e548cc489) built at 20151015-163818
...
</pre>

And then from the searchbird directory, start up a client:

<pre>
$ mvn scala:console
...

scala> import brigade.searchbird.BlockingClient
import brigade.searchbird.BlockingClient

scala> val client = new Client()

scala> client.put("1", "We should ban guns")
org.apache.thrift.TApplicationException: Internal error processing put: 'scala.NotImplementedError: an implementation is missing'
....
</pre>

Paste the following lecture descriptions into the console:

<pre>
client.put("basics", " values functions classes methods inheritance try catch finally expression oriented")
client.put("basics", " case classes objects packages apply update functions are objects (uniform access principle) pattern")
client.put("collections", " lists maps functional combinators (map foreach filter zip")
client.put("pattern", " more functions! partialfunctions more pattern")
client.put("type", " basic types and type polymorphism type inference variance bounds")
client.put("advanced", " advanced types view bounds higher kinded types recursive types structural")
client.put("maven", " all about maven, for building stuff")
client.put("more", " tour of the scala collections")
client.put("testing", " write tests with specs a bdd testing framework for")
client.put("concurrency", " runnable callable threads futures twitter")
client.put("java", " java interop using scala from")
client.put("searchbird", " building a distributed search engine using")
</pre>

We can now perform some searches, which return the keys of the documents that contain the search terms. 

<pre>
> client.search("functions")
res12: Seq[String] = ArrayBuffer(basics)

> client.search("java")
res13: Seq[String] = ArrayBuffer(java)

> client.search("java scala")
res14: Seq[String] = ArrayBuffer(java)

> client.search("functional")
res15: Seq[String] = ArrayBuffer(collections)

> client.search("maven")
res16: Seq[String] = ArrayBuffer(maven)

> client.search("types")
res17: Seq[String] = ArrayBuffer(type, advanced)
</pre>

Our @BlockingClient@ is just a thin wrapper around a standard Finagle @FutureIface@ client. Let's use that now to get some more practice with futures. Recall that if the call returns a @Future@, we have to use a blocking @get()@ call to resolve the value contained within that future. We can use the @Future.collect@ command to make multiple concurrent requests and wait for all of them to succeed:

<pre>
> import com.twitter.util.{Await,Future}
...
> val basicSearchF = client.search("basic")
...
> val collected = Future.collect(Seq(
    client.service.search("types"),
    client.service.search("maven"),
    client.service.search("functional")
  ))
> Await.result(collected)
res18: Seq[Seq[String]] = ArrayBuffer(ArrayBuffer(type, advanced), ArrayBuffer(maven), ArrayBuffer(collections))
</pre>

h2. Bonus: backing our service with a database

While MySQL would not be a great solution for a real-life search engine. Practice non-blocking DB access by adding @finagle-mysql@ to you project and back your service with a database.

<pre>
<dependency>
  <groupId>com.twitter</groupId>
  <artifactId>finagle-mysql_${scala.base.version}</artifactId>
  <version>6.30.0</version>
</dependency>
</pre>

h2. Bonus 2: wrap our service in a JSON API

While Thrift is excellent for machine-to-machine communication, humans may want to interact with our service via HTTP. Add @finagle-http@ to our project and create HTTP endpoints for our thrift methods

<pre>
<dependency>
  <groupId>com.twitter</groupId>
  <artifactId>finagle-http_${scala.base.version}</artifactId>
  <version>6.30.0</version>
</dependency>
</pre>

h2. Bonus 3: distributing our service

On a single machine, our simple in-memory search engine won't be able to search a corpus larger than the size of memory. We'll now venture to remedy this by distributing nodes with a simple sharding scheme. Here's the block diagram:

!searchbird-3.svg(Distributed Searchbird service)!

h3. Abstracting

To aid our work, we'll first introduce another abstraction--an @Index@--in order to decouple the index implementation from the @SearchbirdService@. This is a straightforward refactor. We'll begin by adding an Index file to the build (create the file @searchbird/src/main/scala/com/twitter/searchbird/Index.scala@):

h5. .../Index.scala

<pre>
package brigade.searchbird

import brigade.searchbird.thrift.{SearchbirdService, SearchbirdException}
import com.twitter.finagle.Thrift

import com.twitter.util._
import com.twitter.logging.Logger

import java.util.concurrent.ConcurrentHashMap
import scala.collection.JavaConverters._


trait Index {
  def get(key: String): Future[String]
  def put(key: String, value: String): Future[Unit]
  def search(key: String): Future[Seq[String]]
}

class ResidentIndex extends Index {
  val log = Logger.get(getClass)

  val forward = new ConcurrentHashMap[String, String].asScala
  val reverse = new ConcurrentHashMap[String, Set[String]].asScala

  def get(key: String) = {
    forward.get(key) match {
      case None =>
        log.debug("get %s: miss", key)
        Future.exception(new SearchbirdException("No such key"))
      case Some(value) =>
        log.debug("get %s: hit", key)
        Future(value)
    }
  }

  def put(key: String, value: String) = {
    log.debug("put %s", key)

    forward(key) = value

    // admit only one updater.
    synchronized {
      (Set() ++ value.split(" ")) foreach { token =>
        val current = reverse.get(token) getOrElse Set()
        reverse(token) = current + key
      }
    }

    Future.Unit
  }

  def search(query: String) = Future.value {
    val tokens = query.split(" ")
    val hits = tokens map { token => reverse.getOrElse(token, Set()) }
    val intersected = hits reduceLeftOption { _ & _ } getOrElse Set()
    intersected.toList
  }
}
</pre>

We now convert our thrift service to a simple dispatch mechanism: it provides a thrift interface to any @Index@ instance. This is a powerful abstraction, because it separates the implementation of the service from the implementation of the index. The service no longer has to know any details of the underlying index; the index might be local or might be remote or might be a composite of many remote indices, but the service doesn't care, and the implementation of the index might change without the service changing. 

Replace your @SearchbirdServiceImpl@ class definition with the (much simpler) one below (which no longer contains the index implementation detail). Note initializing a server now takes a second argument, an @Index@.

h5. .../SearchbirdServiceImpl.scala

<pre>
class SearchbirdServiceImpl(index: Index) extends SearchbirdService.FutureIface {
  override def get(key: String) = index.get(key)
  // other methods
}
</pre>

We'll set up our simple distributed system so that there is one distinguished node that coordinates queries to its child nodes. In order to achieve this, we'll need two new @Index@ types. One represents a remote index, the other is a composite index over several other @Index@ instances. This way we can construct the distributed index by instantiating a composite index of the remote indices. Note that both @Index@ types have the same interface, so servers do not need to know whether the index to which they are connected is remote or composite. 

h5. .../Index.scala

In @Index.scala@, define a @CompositeIndex@:

<pre>
class CompositeIndex(indices: Seq[Index]) extends Index {
  require(indices.nonEmpty)

  def get(key: String) = try {
    println("GET", key)
    val queries = indices.map { idx =>
      idx.get(key) map { r => Some(r) } handle { case e => None }
    }

    Future.collect(queries) flatMap { results =>
      println("got results", results.mkString(","))
      results.find { _.isDefined } map { _.get } match {
        case Some(v) => Future.value(v)
        case None => Future.exception(new SearchbirdException("No such key"))
      }
    }
  } catch {
    case NonFatal(e) =>
      println("got exc", e)
      throw e
  }

  def put(key: String, value: String) =
    Future.exception(new SearchbirdException("put() not supported by CompositeIndex"))

  def search(query: String) = {
    val queries = indices.map { _.search(query) rescue { case _=> Future.value(Nil) } }
    Future.collect(queries) map { results => (Set() ++ results.flatten).toList }
  }
}
</pre>

The composite index works over a set of underlying @Index@ instances. Note that it doesn't care how these are actually implemented. This type of composition allows for great flexibility in constructing various querying schemes. We don't define a sharding scheme, and so the composite index doesn't support @put@ operations. These are instead issued directly to the child nodes. @get@ is implemented by querying all of our child nodes and picking the first successful result. If there are none, we throw an exception. Note that since the absence of a value is communicated by throwing an exception, we @handle@ this on the @Future@, converting any exception into a @None@ value. In a real system, we'd probably have proper error codes for missing values rather than using exceptions. Exceptions are convenient and expedient for prototyping, but compose poorly. In order to distinguish between a real exception and a missing value, I have to examine the exception itself. Rather, it is better style to embed this distinction directly in the type of the returned value.

<!-- *_HELP This implementation appears to not give any more scalability than the previous scheme; since the index appears to be completely replicated across all client machines, we can't store a larger amount of data. We'd require a more sophisticated @put()@ scheme that distributed puts to only one index, wouldn't we? Alternately, we could improve throughput by only sending @get()@ requests to one node rather than all nodes._* -->

@search@ works in a similar way as before. Instead of picking the first result, we combine them, ensuring their uniqueness by using a @Set@ construction.

@RemoteIndex@ provides an @Index@ interface to a remote server. 

<pre>

class RemoteIndex(host: String) extends Index {
  val client = Thrift.client.newIface[SearchbirdService.FutureIface](host)

  def get(key: String) = client.get(key)

  def put(key: String, value: String) = client.put(key, value)

  def search(query: String) = client.search(query)
}
</pre>

This constructs a finagle thrift client with some sensible defaults, and just proxies the calls, adjusting the types slightly.

h3. Putting it all together

This is left as an exercise for you! Figure out how to run multiple "shards" of your service have communicate with one another. You'll have
to modify some configuration parameters (right now port 9999 is hard coded for the server) and make other changes.

This design has multiple data abstractions that allow a more modular and scalable implementation:
* The @CompositeIndex@ knows nothing about how its constituent indices are implemented or their underlying data structures; it simply distributes its requests to them. 
* The same @search@ interface (trait) for servers allows a server to query its local data structure (@ResidentIndex@) or distribute queries to other servers (@CompositeIndex@) without needing to know this distinction, which is hidden from the caller.
* The @SearchbirdServiceImpl@ and @Index@ are separate modules now, allowing a simple implementation of the service and separating the implementation of the data structure from the service that accesses it. 
* The design is flexible enough to allow one or many remote indices, located on the local machine or on remote machines. 

<!-- *_HELP Are the possible improvements below accurate?_* -->

Possible improvements to this implementation would include:

* The current implementation sends @put()@ calls to all nodes. Instead, we could use a hash table to send a @put()@ call to only one node and distribute storage across all nodes.
** Note, however, we lose redundancy with this strategy. How could we maintain some redundancy yet not require full replication? 
* We aren't doing anything interesting with any failures in the system (we aren't processing any exceptions, for instance). 
